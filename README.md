# üöÄ CV Optimizer (Estilo Resumego)

Optimiza tu curr√≠culum vitae (CV) con Inteligencia Artificial local (Llama 3) para maximizar su impacto y compatibilidad con los Sistemas de Seguimiento de Candidatos (ATS).

## üåü Caracter√≠sticas Principales

Este proyecto ofrece una soluci√≥n completa para el procesamiento y la mejora de CVs, construida sobre una pila tecnol√≥gica moderna y localizable:

*   **Soporte Multiling√ºe:** Procesa CVs en **espa√±ol e ingl√©s**.
*   **Extracci√≥n Flexible:** Permite subir el CV en formato **PDF** o pegar el texto plano directamente.
*   **Detecci√≥n de Industria:** Identifica autom√°ticamente la industria del candidato para aplicar optimizaciones contextuales.
*   **Optimizaci√≥n con LLM Local:** Utiliza **Llama 3** a trav√©s de **Ollama** para reescribir y mejorar los puntos de experiencia, transform√°ndolos en logros cuantificables.
*   **Salida ATS-Friendly:** Genera un CV optimizado en formato **HTML limpio**, dise√±ado para ser f√°cilmente parseado por los sistemas ATS.
*   **Despliegue Sencillo:** Listo para ser ejecutado con **Docker** y `docker-compose`, incluyendo el servicio de Ollama.

## üß† Funcionamiento de la Optimizaci√≥n

El proceso de optimizaci√≥n se centra en tres etapas clave para asegurar un CV de alto impacto:

1.  **Extracci√≥n y Segmentaci√≥n:** Se extrae el texto del PDF (o se usa el texto pegado) y se segmenta en secciones clave (Experiencia, Educaci√≥n, Habilidades).
2.  **An√°lisis Contextual:**
    *   Se detecta el idioma principal del CV.
    *   Se analiza el contenido para determinar la **industria** (e.g., Tech, Finance, HR) mediante un sistema de palabras clave.
3.  **Mejora de Logros (Llama 3):**
    *   Cada punto de la secci√≥n de Experiencia es enviado a Llama 3 con un *prompt* de ingenier√≠a espec√≠fico.
    *   El modelo reescribe el punto, enfoc√°ndose en el uso de **verbos de acci√≥n fuertes** y sugiriendo la inclusi√≥n de **m√©tricas y resultados cuantificables** (el lenguaje que buscan los ATS).
4.  **Generaci√≥n Final:** El contenido mejorado se integra en una plantilla HTML simple y estructurada, ideal para ser le√≠do por humanos y m√°quinas (ATS).

## ‚ñ∂Ô∏è Gu√≠a de Inicio R√°pido (Recomendado)

La forma m√°s sencilla de poner en marcha el CV Optimizer es utilizando Docker Compose, ya que gestiona autom√°ticamente la aplicaci√≥n Streamlit y el servidor de Ollama.

### 1. Requisitos Previos

Aseg√∫rate de tener instalado:
*   **Docker** y **Docker Compose** (o Docker Desktop).

### 2. Descarga del Modelo Llama 3

Antes de ejecutar el contenedor, debes asegurarte de que el modelo `llama3` est√© disponible en tu instancia de Ollama.

```bash
# Si tienes Ollama instalado localmente
ollama pull llama3
```

### 3. Ejecuci√≥n con Docker Compose

Desde el directorio ra√≠z del proyecto, ejecuta:

```bash
docker-compose up --build
```

Esto iniciar√° dos servicios: `ollama` y `cv-optimizer`.

### 4. Acceso a la Aplicaci√≥n

Una vez que ambos servicios est√©n activos, accede a la aplicaci√≥n Streamlit en tu navegador:

```
http://localhost:8501
```

## ‚öôÔ∏è Instalaci√≥n Local (Avanzado)

Si prefieres ejecutar la aplicaci√≥n directamente en tu entorno Python:

### 1. Requisitos

*   Python 3.10+
*   Un servidor **Ollama** ejecut√°ndose localmente en `http://localhost:11434` con el modelo `llama3` descargado.

### 2. Configuraci√≥n del Entorno

```bash
# Crear y activar un entorno virtual
python3 -m venv venv
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt

# Descargar modelos de spaCy
python -m spacy download es_core_news_sm
python -m spacy download en_core_web_sm
```

### 3. Ejecuci√≥n de la Aplicaci√≥n

```bash
streamlit run app.py
```

## üõ†Ô∏è Estructura del Proyecto

| Archivo | Descripci√≥n |
| :--- | :--- |
| `app.py` | Aplicaci√≥n principal Streamlit. Maneja la interfaz de usuario, la carga de archivos y la visualizaci√≥n de resultados. |
| `cv_processor.py` | L√≥gica central de procesamiento. Contiene funciones para la detecci√≥n de idioma, parsing de secciones, extracci√≥n de habilidades y la comunicaci√≥n con Llama 3. |
| `industry_keywords.json` | Base de datos de palabras clave y verbos de acci√≥n para la detecci√≥n de industria y la optimizaci√≥n de *prompts*. |
| `requirements.txt` | Dependencias de Python necesarias (`streamlit`, `spacy`, `pdfplumber`, `requests`, etc.). |
| `Dockerfile` | Instrucciones para construir la imagen Docker de la aplicaci√≥n. |
| `docker-compose.yml` | Configuraci√≥n para ejecutar la aplicaci√≥n junto con el servicio de Ollama. |

## üìú Historial de Cambios

Para ver el detalle de todas las actualizaciones y mejoras, consulta el archivo [CHANGELOG.md](CHANGELOG.md).

## üìù Licencia

Este proyecto est√° bajo la licencia MIT. Consulta el archivo `LICENSE` para m√°s detalles.
